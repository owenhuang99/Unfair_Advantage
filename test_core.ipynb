{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8259648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Link Ingestion MVP (Notebook-Ready)\n",
    "# =========================\n",
    "# deps: openai, trafilatura, bs4, lxml or html5lib, python-dotenv, pandas, requests\n",
    "# usage (quick start at bottom of this cell)\n",
    "import os, re, json, datetime, typing as T\n",
    "from dataclasses import dataclass\n",
    "from urllib.parse import urlparse\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import trafilatura\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Load environment (expects OPENAI_API_KEY) ----\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effff292",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =========================\n",
    "# Config (edit as you like)\n",
    "# =========================\n",
    "MODEL_WITH_WEB = os.getenv(\"MODEL_WITH_WEB\", \"gpt-4o-mini\")     # has web tool on eligible accounts\n",
    "MODEL_FALLBACK = os.getenv(\"MODEL_FALLBACK\", \"gpt-4.1-mini\")    # local LLM fallback\n",
    "TAXONOMY_PATH  = os.getenv(\"TAXONOMY_PATH\", \"taxonomy.json\")    # where allowed lists persist\n",
    "CSV_PATH       = os.getenv(\"CSV_PATH\", \"links_store.csv\")       # where your DataFrame persists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4adba6",
   "metadata": {},
   "source": [
    "# MVP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a7df4b",
   "metadata": {},
   "source": [
    "## Function 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEFAULT_HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:128.0) Gecko/20100101 Firefox/128.0\"\n",
    "}\n",
    "\n",
    "STRICT_JSON_RULES = (\n",
    "    \"Return STRICT JSON with keys: \"\n",
    "    '[\"title\",\"author\",\"publish_date\",\"categories\",\"tags\",\"tldr\",\"language\",\"citations\",\"confidence_notes\"]. '\n",
    "    \"categories=1–3 short labels; tags=5–12 keywords; tldr=3–6 crisp bullets; \"\n",
    "    \"language=two-letter ISO code; citations=list of {title,url}; \"\n",
    "    \"confidence_notes=1–2 short sentences. No markdown—JSON only.\"\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Types\n",
    "# =========================\n",
    "@dataclass\n",
    "class PageContent:\n",
    "    url: str\n",
    "    domain: str\n",
    "    title: T.Optional[str]\n",
    "    author: T.Optional[str]\n",
    "    publish_date: T.Optional[str]\n",
    "    text: str\n",
    "    html_len: int\n",
    "    text_len: int\n",
    "\n",
    "# =========================\n",
    "# Helpers: parsing & fetching\n",
    "# =========================\n",
    "def _best_bs4_parser():\n",
    "    try:\n",
    "        import lxml  # noqa\n",
    "        return \"lxml\"\n",
    "    except Exception:\n",
    "        try:\n",
    "            import html5lib  # noqa\n",
    "            return \"html5lib\"\n",
    "        except Exception:\n",
    "            return \"html.parser\"\n",
    "\n",
    "def _safe_json_loads(text: str) -> dict:\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        m = re.search(r\"\\{.*\\}\", text, re.S)\n",
    "        return json.loads(m.group(0)) if m else {\"error\": \"Non-JSON output\", \"raw\": text[:1200]}\n",
    "\n",
    "def _fetch_html(url: str) -> str:\n",
    "    r = requests.get(url, headers=DEFAULT_HEADERS, timeout=25)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "def _guess_meta(soup: BeautifulSoup) -> dict:\n",
    "    meta = {\"title\": None, \"author\": None, \"publish_date\": None}\n",
    "    # title\n",
    "    if soup.title and soup.title.string:\n",
    "        meta[\"title\"] = soup.title.string.strip()\n",
    "    ogt = soup.find(\"meta\", property=\"og:title\")\n",
    "    if ogt and ogt.get(\"content\"):\n",
    "        meta[\"title\"] = ogt[\"content\"].strip()\n",
    "    # author\n",
    "    for k in [\"author\", \"article:author\", \"og:article:author\"]:\n",
    "        m = soup.find(\"meta\", attrs={\"name\": k}) or soup.find(\"meta\", attrs={\"property\": k})\n",
    "        if m and m.get(\"content\"):\n",
    "            meta[\"author\"] = m[\"content\"].strip(); break\n",
    "    # date\n",
    "    for k in [\"article:published_time\", \"og:published_time\", \"pubdate\", \"publish-date\", \"date\"]:\n",
    "        m = soup.find(\"meta\", attrs={\"name\": k}) or soup.find(\"meta\", attrs={\"property\": k})\n",
    "        if m and m.get(\"content\"):\n",
    "            meta[\"publish_date\"] = m[\"content\"].strip(); break\n",
    "    if meta[\"publish_date\"] is None:\n",
    "        t = soup.find(\"time\")\n",
    "        if t and (t.get(\"datetime\") or t.text):\n",
    "            meta[\"publish_date\"] = (t.get(\"datetime\") or t.text).strip()\n",
    "    return meta\n",
    "\n",
    "def extract_readable_text(url: str) -> PageContent:\n",
    "    html = _fetch_html(url)\n",
    "    text = (trafilatura.extract(html, include_comments=False, include_tables=False, favor_precision=True) or \"\").strip()\n",
    "\n",
    "    if len(text) < 200:\n",
    "        PARSER = _best_bs4_parser()\n",
    "        soup = BeautifulSoup(html, PARSER)\n",
    "        for tag in soup([\"script\",\"style\",\"noscript\",\"header\",\"footer\",\"nav\",\"aside\"]):\n",
    "            tag.extract()\n",
    "        text = soup.get_text(\"\\n\", strip=True)\n",
    "\n",
    "    PARSER = _best_bs4_parser()\n",
    "    soup_full = BeautifulSoup(html, PARSER)\n",
    "    meta = _guess_meta(soup_full)\n",
    "\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return PageContent(\n",
    "        url=url,\n",
    "        domain=urlparse(url).netloc,\n",
    "        title=meta[\"title\"],\n",
    "        author=meta[\"author\"],\n",
    "        publish_date=meta[\"publish_date\"],\n",
    "        text=text,\n",
    "        html_len=len(html or \"\"),\n",
    "        text_len=len(text or \"\")\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# Taxonomy persistence\n",
    "# =========================\n",
    "def load_taxonomy(path: str = TAXONOMY_PATH) -> dict:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        return {\"categories\": [], \"tags\": []}\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    # ensure keys\n",
    "    data.setdefault(\"categories\", [])\n",
    "    data.setdefault(\"tags\", [])\n",
    "    return data\n",
    "\n",
    "def save_taxonomy(categories: T.List[str], tags: T.List[str], path: str = TAXONOMY_PATH) -> None:\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"categories\": categories, \"tags\": tags}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# =========================\n",
    "# Matching & evolving lists\n",
    "# =========================\n",
    "def _normalize_token(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s.strip().lower())\n",
    "\n",
    "def update_matches(candidates: T.List[str], allowed: T.List[str], max_k: int) -> T.Tuple[T.List[str], T.List[str]]:\n",
    "    \"\"\"\n",
    "    Try to match candidates against allowed list.\n",
    "    If no match found for a candidate, add it as a new allowed term.\n",
    "    Returns (final_matches, updated_allowed_list).\n",
    "    \"\"\"\n",
    "    allowed_norm = { _normalize_token(a): a for a in allowed }\n",
    "    matches, updated_allowed = [], allowed.copy()\n",
    "    seen = set()\n",
    "\n",
    "    for c in candidates:\n",
    "        if not isinstance(c, str):\n",
    "            continue\n",
    "        c_clean = c.strip()\n",
    "        if not c_clean:\n",
    "            continue\n",
    "        c_norm = _normalize_token(c_clean)\n",
    "\n",
    "        hit = None\n",
    "        # exact\n",
    "        if c_norm in allowed_norm:\n",
    "            hit = allowed_norm[c_norm]\n",
    "        else:\n",
    "            # substring match either way\n",
    "            for an_norm, raw in allowed_norm.items():\n",
    "                if c_norm in an_norm or an_norm in c_norm:\n",
    "                    hit = raw; break\n",
    "        if hit:\n",
    "            if hit not in seen:\n",
    "                matches.append(hit); seen.add(hit)\n",
    "        else:\n",
    "            # new term → append to allowed\n",
    "            if c_clean not in updated_allowed:\n",
    "                updated_allowed.append(c_clean)\n",
    "            if c_clean not in seen:\n",
    "                matches.append(c_clean); seen.add(c_clean)\n",
    "\n",
    "        if len(matches) >= max_k:\n",
    "            break\n",
    "\n",
    "    return matches, updated_allowed\n",
    "\n",
    "# =========================\n",
    "# LLM calls (web tool → local fallback)\n",
    "# =========================\n",
    "def analyze_link_with_web_tool(url: str, allowed_categories: T.List[str], allowed_tags: T.List[str]) -> dict:\n",
    "    if not hasattr(client, \"responses\"):\n",
    "        raise RuntimeError(\"responses_api_unavailable\")\n",
    "\n",
    "    user_prompt = (\n",
    "        f\"{STRICT_JSON_RULES}\\n\\n\"\n",
    "        f\"When labeling categories and tags, prefer from the lists below when semantically appropriate.\\n\"\n",
    "        f\"Allowed categories: {json.dumps(allowed_categories[:50])}\\n\"\n",
    "        f\"Allowed tags: {json.dumps(allowed_tags[:200])}\\n\\n\"\n",
    "        f\"Read this URL and summarize with citations: {url}\"\n",
    "    )\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL_WITH_WEB,\n",
    "        tools=[{\"type\": \"web_search\"}],\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise analyst that reads the provided URL using the web tool.\"},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "    )\n",
    "    output_text = getattr(resp, \"output_text\", getattr(resp, \"output\", \"\"))\n",
    "    return _safe_json_loads(output_text)\n",
    "\n",
    "def summarize_local_content(page: PageContent, allowed_categories: T.List[str], allowed_tags: T.List[str]) -> dict:\n",
    "    payload = {\n",
    "        \"source_url\": page.url,\n",
    "        \"detected_title\": page.title,\n",
    "        \"detected_author\": page.author,\n",
    "        \"detected_publish_date\": page.publish_date,\n",
    "        \"article_text\": page.text[:22_000],\n",
    "        \"allowed_categories\": allowed_categories[:50],\n",
    "        \"allowed_tags\": allowed_tags[:200]\n",
    "    }\n",
    "    if hasattr(client, \"responses\"):\n",
    "        resp = client.responses.create(\n",
    "            model=MODEL_FALLBACK,\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": STRICT_JSON_RULES},\n",
    "                {\"role\": \"user\", \"content\": json.dumps(payload)}\n",
    "            ],\n",
    "        )\n",
    "        output_text = getattr(resp, \"output_text\", getattr(resp, \"output\", \"\"))\n",
    "        return _safe_json_loads(output_text)\n",
    "    else:\n",
    "        # very old fallback\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": STRICT_JSON_RULES},\n",
    "            {\"role\": \"user\", \"content\": json.dumps(payload)},\n",
    "        ]\n",
    "        cc = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "        return _safe_json_loads(cc.choices[0].message.content)\n",
    "\n",
    "# =========================\n",
    "# Public API: main function\n",
    "# =========================\n",
    "def analyze_link_plus(\n",
    "    url: str,\n",
    "    allowed_categories: T.List[str] = None,\n",
    "    allowed_tags: T.List[str] = None,\n",
    "    force_local: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Returns a normalized record (dict) and includes updated taxonomy under _taxonomy.\n",
    "    Keys:\n",
    "        fetched_at_utc, url, domain, headline, categories, tags, tldr (list),\n",
    "        content_text, source_title, author, publish_date, _source, _taxonomy\n",
    "    \"\"\"\n",
    "    assert url.startswith(\"http\"), \"Pass a valid http(s) URL.\"\n",
    "    allowed_categories = allowed_categories or []\n",
    "    allowed_tags = allowed_tags or []\n",
    "\n",
    "    # parse locally first so you can verify and fall back if needed\n",
    "    page = extract_readable_text(url)\n",
    "\n",
    "    # LLM metadata\n",
    "    try:\n",
    "        if force_local:\n",
    "            raise RuntimeError(\"forced_local\")\n",
    "        llm_data = analyze_link_with_web_tool(url, allowed_categories, allowed_tags)\n",
    "        mode = \"openai_web_tool\"\n",
    "        model_used = MODEL_WITH_WEB\n",
    "    except Exception:\n",
    "        if page.text_len < 200:\n",
    "            raise RuntimeError(\"Could not extract enough text; page may be paywalled or script-rendered.\")\n",
    "        llm_data = summarize_local_content(page, allowed_categories, allowed_tags)\n",
    "        mode = \"local_fallback\"\n",
    "        model_used = MODEL_FALLBACK\n",
    "\n",
    "    # normalize fields\n",
    "    fetched_at_utc = datetime.datetime.utcnow().isoformat() + \"Z\"\n",
    "    raw_categories = llm_data.get(\"categories\") or []\n",
    "    raw_tags = llm_data.get(\"tags\") or []\n",
    "    tldr = llm_data.get(\"tldr\") or []\n",
    "\n",
    "    # TLDR as list\n",
    "    if isinstance(tldr, str):\n",
    "        parts = [p.strip(\" -•\\t\") for p in re.split(r\"[\\n•\\-]+\", tldr) if p.strip()]\n",
    "        tldr = parts[:6] if parts else [llm_data.get(\"tldr\", \"\")]\n",
    "\n",
    "    # evolve taxonomy\n",
    "    categories, updated_categories = update_matches(raw_categories, allowed_categories, max_k=3)\n",
    "    tags, updated_tags = update_matches(raw_tags, allowed_tags, max_k=12)\n",
    "\n",
    "    record = {\n",
    "        \"fetched_at_utc\": fetched_at_utc,\n",
    "        \"url\": page.url,\n",
    "        \"domain\": page.domain,\n",
    "        \"headline\": (llm_data.get(\"title\") or page.title or \"\").strip()[:300],\n",
    "        \"categories\": categories,\n",
    "        \"tags\": tags,\n",
    "        \"tldr\": tldr,\n",
    "        \"content_text\": page.text,    # full parsed text so you can verify LLM output\n",
    "        \"source_title\": page.title,\n",
    "        \"author\": llm_data.get(\"author\") or page.author,\n",
    "        \"publish_date\": llm_data.get(\"publish_date\") or page.publish_date,\n",
    "        \"_source\": {\"mode\": mode, \"model\": model_used},\n",
    "        \"_taxonomy\": {\n",
    "            \"updated_categories\": updated_categories,\n",
    "            \"updated_tags\": updated_tags\n",
    "        }\n",
    "    }\n",
    "    return record\n",
    "\n",
    "# =========================\n",
    "# DataFrame Store (in-memory + CSV)\n",
    "# =========================\n",
    "COLUMNS = [\n",
    "    \"fetched_at_utc\",\"url\",\"domain\",\"headline\",\"categories\",\"tags\",\"tldr\",\n",
    "    \"content_text\",\"source_title\",\"author\",\"publish_date\"\n",
    "]\n",
    "\n",
    "def init_store() -> pd.DataFrame:\n",
    "    return pd.DataFrame(columns=COLUMNS)\n",
    "\n",
    "def append_record(df: pd.DataFrame, record: dict) -> pd.DataFrame:\n",
    "    # store lists as Python lists (dtype=object)\n",
    "    row = {k: record.get(k, None) for k in COLUMNS}\n",
    "    return pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "def save_csv(df: pd.DataFrame, path: str = CSV_PATH) -> None:\n",
    "    df2 = df.copy()\n",
    "    for col in [\"categories\",\"tags\",\"tldr\"]:\n",
    "        if col in df2.columns:\n",
    "            df2[col] = df2[col].apply(lambda x: x if isinstance(x, str) else json.dumps(x, ensure_ascii=False))\n",
    "    df2.to_csv(path, index=False)\n",
    "\n",
    "def load_csv(path: str = CSV_PATH) -> pd.DataFrame:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        return init_store()\n",
    "    df = pd.read_csv(path)\n",
    "    for col in [\"categories\",\"tags\",\"tldr\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda s: json.loads(s) if isinstance(s, str) and s.startswith(\"[\") else [])\n",
    "    return df\n",
    "\n",
    "def simple_search(df: pd.DataFrame, query: str, top_n: int = 50) -> pd.DataFrame:\n",
    "    q = (query or \"\").lower().strip()\n",
    "    if not q:\n",
    "        return df.head(top_n)\n",
    "    mask = (\n",
    "        df[\"headline\"].fillna(\"\").str.lower().str.contains(q) |\n",
    "        df[\"url\"].fillna(\"\").str.lower().str.contains(q) |\n",
    "        df[\"domain\"].fillna(\"\").str.lower().str.contains(q) |\n",
    "        df[\"content_text\"].fillna(\"\").str.lower().str.contains(q) |\n",
    "        df[\"tags\"].astype(str).str.lower().str.contains(q) |\n",
    "        df[\"categories\"].astype(str).str.lower().str.contains(q)\n",
    "    )\n",
    "    return df[mask].head(top_n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5612d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/_gt22h7503dgw67xjtv9ccn00000gn/T/ipykernel_6815/3911997558.py:291: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  fetched_at_utc = datetime.datetime.utcnow().isoformat() + \"Z\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fetched_at_utc</th>\n",
       "      <th>headline</th>\n",
       "      <th>categories</th>\n",
       "      <th>tags</th>\n",
       "      <th>tldr</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-13T15:07:09.608280Z</td>\n",
       "      <td>LLM-as-a-Judge Simply Explained: The Complete ...</td>\n",
       "      <td>[AI/ML, Product, Startups]</td>\n",
       "      <td>[LLM, RAG, LangGraph, Agentic AI, Vector DB, P...</td>\n",
       "      <td>[LLM-as-a-Judge automates LLM evaluation, enha...</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fetched_at_utc  \\\n",
       "0  2025-09-13T15:07:09.608280Z   \n",
       "\n",
       "                                            headline  \\\n",
       "0  LLM-as-a-Judge Simply Explained: The Complete ...   \n",
       "\n",
       "                   categories  \\\n",
       "0  [AI/ML, Product, Startups]   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [LLM, RAG, LangGraph, Agentic AI, Vector DB, P...   \n",
       "\n",
       "                                                tldr  \\\n",
       "0  [LLM-as-a-Judge automates LLM evaluation, enha...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.confident-ai.com/blog/why-llm-as-a...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Store record incrementally in the CSV\n",
    "\n",
    "# =========================\n",
    "# URL canonicalization (for stable dedupe)\n",
    "# =========================\n",
    "from urllib.parse import urlparse, parse_qsl, urlencode, urlunparse\n",
    "\n",
    "_STRIP_PARAMS = {\n",
    "    \"utm_source\",\"utm_medium\",\"utm_campaign\",\"utm_term\",\"utm_content\",\n",
    "    \"utm_name\",\"utm_id\",\"gclid\",\"gclsrc\",\"fbclid\",\"mc_cid\",\"mc_eid\"\n",
    "}\n",
    "\n",
    "def canonicalize_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize URL for dedupe:\n",
    "    - lowercase scheme/host\n",
    "    - remove common tracking params\n",
    "    - sort remaining query params\n",
    "    - strip trailing slash (except root)\n",
    "    \"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    scheme = (parsed.scheme or \"https\").lower()\n",
    "    netloc = parsed.netloc.lower()\n",
    "    path = parsed.path or \"/\"\n",
    "    # normalize trailing slash\n",
    "    if path != \"/\" and path.endswith(\"/\"):\n",
    "        path = path[:-1]\n",
    "\n",
    "    # clean & sort query\n",
    "    q = []\n",
    "    for k, v in parse_qsl(parsed.query, keep_blank_values=True):\n",
    "        if k.lower() in _STRIP_PARAMS:\n",
    "            continue\n",
    "        q.append((k, v))\n",
    "    q.sort(key=lambda kv: kv[0].lower())\n",
    "    query = urlencode(q, doseq=True)\n",
    "\n",
    "    canon = urlunparse((scheme, netloc, path, \"\", query, \"\"))\n",
    "    return canon\n",
    "\n",
    "# =========================\n",
    "# DataFrame Store (CSV cache with dedupe by url_canonical)\n",
    "# =========================\n",
    "COLUMNS = [\n",
    "    \"fetched_at_utc\",\"url\",\"url_canonical\",\"domain\",\"headline\",\n",
    "    \"categories\",\"tags\",\"tldr\",\"content_text\",\"source_title\",\"author\",\"publish_date\"\n",
    "]\n",
    "\n",
    "def init_store() -> pd.DataFrame:\n",
    "    return pd.DataFrame(columns=COLUMNS)\n",
    "\n",
    "def _ensure_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # add any missing columns (for backward compatibility)\n",
    "    for col in COLUMNS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    # backfill url_canonical if missing/empty\n",
    "    if df[\"url_canonical\"].isna().any() or (df[\"url_canonical\"] == \"\").any():\n",
    "        df[\"url_canonical\"] = df.apply(\n",
    "            lambda r: canonicalize_url(r[\"url\"]) if pd.isna(r[\"url_canonical\"]) or r[\"url_canonical\"] == \"\" else r[\"url_canonical\"],\n",
    "            axis=1\n",
    "        )\n",
    "    return df[COLUMNS]\n",
    "\n",
    "def save_csv(df: pd.DataFrame, path: str = CSV_PATH) -> None:\n",
    "    df2 = df.copy()\n",
    "    # lists -> JSON strings for portability\n",
    "    for col in [\"categories\",\"tags\",\"tldr\"]:\n",
    "        if col in df2.columns:\n",
    "            df2[col] = df2[col].apply(lambda x: x if isinstance(x, str) else json.dumps(x, ensure_ascii=False))\n",
    "    df2.to_csv(path, index=False)\n",
    "\n",
    "def load_csv(path: str = CSV_PATH) -> pd.DataFrame:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        return init_store()\n",
    "    df = pd.read_csv(path)\n",
    "    # restore lists\n",
    "    for col in [\"categories\",\"tags\",\"tldr\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda s: json.loads(s) if isinstance(s, str) and s.startswith(\"[\") else ([] if pd.isna(s) else s))\n",
    "    df = _ensure_columns(df)\n",
    "    return df\n",
    "\n",
    "def append_record(df: pd.DataFrame, record: dict) -> pd.DataFrame:\n",
    "    row = {\n",
    "        \"fetched_at_utc\": record.get(\"fetched_at_utc\"),\n",
    "        \"url\": record.get(\"url\"),\n",
    "        \"url_canonical\": canonicalize_url(record.get(\"url\",\"\")),\n",
    "        \"domain\": record.get(\"domain\"),\n",
    "        \"headline\": record.get(\"headline\"),\n",
    "        \"categories\": record.get(\"categories\"),\n",
    "        \"tags\": record.get(\"tags\"),\n",
    "        \"tldr\": record.get(\"tldr\"),\n",
    "        \"content_text\": record.get(\"content_text\"),\n",
    "        \"source_title\": record.get(\"source_title\"),\n",
    "        \"author\": record.get(\"author\"),\n",
    "        \"publish_date\": record.get(\"publish_date\"),\n",
    "    }\n",
    "    return pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "def get_cached_row(df: pd.DataFrame, url: str) -> T.Optional[dict]:\n",
    "    canon = canonicalize_url(url)\n",
    "    hits = df[df[\"url_canonical\"] == canon]\n",
    "    if len(hits) == 0:\n",
    "        return None\n",
    "    rec = hits.iloc[0].to_dict()\n",
    "    # ensure list types for convenience\n",
    "    for col in [\"categories\",\"tags\",\"tldr\"]:\n",
    "        v = rec.get(col)\n",
    "        if isinstance(v, str):\n",
    "            try:\n",
    "                rec[col] = json.loads(v) if v.startswith(\"[\") else [v]\n",
    "            except Exception:\n",
    "                rec[col] = [v]\n",
    "    return rec\n",
    "\n",
    "# =========================\n",
    "# Orchestrator: ingest OR fetch from cache\n",
    "# =========================\n",
    "def ingest_or_fetch(\n",
    "    url: str,\n",
    "    taxonomy_path: str = TAXONOMY_PATH,\n",
    "    csv_path: str = CSV_PATH,\n",
    "    force_reingest: bool = False,\n",
    ") -> T.Tuple[dict, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    If canonical URL exists in CSV, return the cached row (and skip LLM).\n",
    "    Else run analyze_link_plus(), update taxonomy JSON, append 1 row to CSV, and return the new row.\n",
    "    Returns: (row_as_dict, updated_df)\n",
    "    \"\"\"\n",
    "    # 0) load CSV (cache) and taxonomy\n",
    "    df = load_csv(csv_path)\n",
    "    tax = load_taxonomy(taxonomy_path)\n",
    "    tax.setdefault(\"categories\", [])\n",
    "    tax.setdefault(\"tags\", [])\n",
    "\n",
    "    # 1) cached?\n",
    "    if not force_reingest:\n",
    "        cached = get_cached_row(df, url)\n",
    "        if cached is not None:\n",
    "            return cached, df  # nothing else to do\n",
    "\n",
    "    # 2) not cached → analyze\n",
    "    rec = analyze_link_plus(\n",
    "        url,\n",
    "        allowed_categories=tax[\"categories\"],\n",
    "        allowed_tags=tax[\"tags\"]\n",
    "    )\n",
    "\n",
    "    # 3) update taxonomy (evolving lists)\n",
    "    tax[\"categories\"] = rec[\"_taxonomy\"][\"updated_categories\"]\n",
    "    tax[\"tags\"] = rec[\"_taxonomy\"][\"updated_tags\"]\n",
    "    save_taxonomy(tax[\"categories\"], tax[\"tags\"], taxonomy_path)\n",
    "\n",
    "    # 4) append to CSV cache\n",
    "    df = append_record(df, rec)\n",
    "    save_csv(df, csv_path)\n",
    "\n",
    "    # 5) return a compact dict consistent with CSV row formatting\n",
    "    row = {\n",
    "        \"fetched_at_utc\": rec[\"fetched_at_utc\"],\n",
    "        \"url\": rec[\"url\"],\n",
    "        \"url_canonical\": canonicalize_url(rec[\"url\"]),\n",
    "        \"domain\": rec[\"domain\"],\n",
    "        \"headline\": rec[\"headline\"],\n",
    "        \"categories\": rec[\"categories\"],\n",
    "        \"tags\": rec[\"tags\"],\n",
    "        \"tldr\": rec[\"tldr\"],\n",
    "        \"content_text\": rec[\"content_text\"],\n",
    "        \"source_title\": rec[\"source_title\"],\n",
    "        \"author\": rec[\"author\"],\n",
    "        \"publish_date\": rec[\"publish_date\"],\n",
    "    }\n",
    "    return rec, row, df\n",
    "\n",
    "# =========================\n",
    "# Quick demo — mimics your preferred usage\n",
    "# =========================\n",
    "test_url = \"https://www.confident-ai.com/blog/why-llm-as-a-judge-is-the-best-llm-evaluation-method\"\n",
    "\n",
    "rec, row, df = ingest_or_fetch(test_url)\n",
    "# `row` is the single record (dict); `df` is the full accumulated store\n",
    "# If you run again with the same URL, it will return from cache and skip LLM.\n",
    "\n",
    "# show the row as a one-line DataFrame (your key fields)\n",
    "pd.DataFrame([{\n",
    "    \"fetched_at_utc\": row[\"fetched_at_utc\"],\n",
    "    \"headline\": row[\"headline\"],\n",
    "    \"categories\": row[\"categories\"],\n",
    "    \"tags\": row[\"tags\"],\n",
    "    \"tldr\": row[\"tldr\"],\n",
    "    \"url\": row[\"url\"]\n",
    "}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad1b520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fetched_at_utc</th>\n",
       "      <th>url</th>\n",
       "      <th>url_canonical</th>\n",
       "      <th>domain</th>\n",
       "      <th>headline</th>\n",
       "      <th>categories</th>\n",
       "      <th>tags</th>\n",
       "      <th>tldr</th>\n",
       "      <th>content_text</th>\n",
       "      <th>source_title</th>\n",
       "      <th>author</th>\n",
       "      <th>publish_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-13T15:05:07.059924Z</td>\n",
       "      <td>https://medium.com/data-science/from-data-scie...</td>\n",
       "      <td>https://medium.com/data-science/from-data-scie...</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>From Data Scientist to ML / AI Product Manager</td>\n",
       "      <td>[AI/ML, Product, Career]</td>\n",
       "      <td>[ML Product Manager, AI Product Manager, Data ...</td>\n",
       "      <td>[Transitioning from Data Scientist to ML/AI Pr...</td>\n",
       "      <td>From Data Scientist to ML / AI Product Manager...</td>\n",
       "      <td>From Data Scientist to ML / AI Product Manager</td>\n",
       "      <td>Anna Via</td>\n",
       "      <td>2024-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-13T15:07:09.608280Z</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "      <td>www.confident-ai.com</td>\n",
       "      <td>LLM-as-a-Judge Simply Explained: The Complete ...</td>\n",
       "      <td>[AI/ML, Product, Startups]</td>\n",
       "      <td>[LLM, RAG, LangGraph, Agentic AI, Vector DB, P...</td>\n",
       "      <td>[LLM-as-a-Judge automates LLM evaluation, enha...</td>\n",
       "      <td>Your LLM app is streaming out tokens faster th...</td>\n",
       "      <td>LLM-as-a-Judge Simply Explained: The Complete ...</td>\n",
       "      <td>Jeffrey Ip</td>\n",
       "      <td>2025-08-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fetched_at_utc  \\\n",
       "0  2025-09-13T15:05:07.059924Z   \n",
       "1  2025-09-13T15:07:09.608280Z   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://medium.com/data-science/from-data-scie...   \n",
       "1  https://www.confident-ai.com/blog/why-llm-as-a...   \n",
       "\n",
       "                                       url_canonical                domain  \\\n",
       "0  https://medium.com/data-science/from-data-scie...            medium.com   \n",
       "1  https://www.confident-ai.com/blog/why-llm-as-a...  www.confident-ai.com   \n",
       "\n",
       "                                            headline  \\\n",
       "0     From Data Scientist to ML / AI Product Manager   \n",
       "1  LLM-as-a-Judge Simply Explained: The Complete ...   \n",
       "\n",
       "                   categories  \\\n",
       "0    [AI/ML, Product, Career]   \n",
       "1  [AI/ML, Product, Startups]   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [ML Product Manager, AI Product Manager, Data ...   \n",
       "1  [LLM, RAG, LangGraph, Agentic AI, Vector DB, P...   \n",
       "\n",
       "                                                tldr  \\\n",
       "0  [Transitioning from Data Scientist to ML/AI Pr...   \n",
       "1  [LLM-as-a-Judge automates LLM evaluation, enha...   \n",
       "\n",
       "                                        content_text  \\\n",
       "0  From Data Scientist to ML / AI Product Manager...   \n",
       "1  Your LLM app is streaming out tokens faster th...   \n",
       "\n",
       "                                        source_title      author publish_date  \n",
       "0     From Data Scientist to ML / AI Product Manager    Anna Via   2024-04-03  \n",
       "1  LLM-as-a-Judge Simply Explained: The Complete ...  Jeffrey Ip   2025-08-21  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c03e042",
   "metadata": {},
   "source": [
    "## Function 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396340da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# MVP Flashcards (Single CSV + Swipe Queue)\n",
    "# =========================\n",
    "\n",
    "import os, re, json, hashlib, datetime, typing as T\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ---- OpenAI client ----\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "CARDS_CSV_PATH = os.getenv(\"CARDS_CSV_PATH\", \"cards_store.csv\")\n",
    "MODEL_FOR_CARDS = os.getenv(\"MODEL_FOR_CARDS\", \"gpt-4.1-mini\")  # lightweight, cheap\n",
    "MAX_TEXT_CHARS = int(os.getenv(\"MAX_TEXT_CHARS\", \"8000\"))       # cap article text sent to LLM\n",
    "\n",
    "# =========================\n",
    "# CSV schema\n",
    "# =========================\n",
    "CARD_COLUMNS = [\n",
    "    \"card_id\",         # pk (sha1 of url_canonical + \"\\n\" + normalized_question)\n",
    "    \"url_canonical\",   # article key\n",
    "    \"question\",\n",
    "    \"answer\",\n",
    "    \"learned\",         # bool\n",
    "    \"created_at_utc\"   # ISO str\n",
    "]\n",
    "\n",
    "def _ensure_cards_csv(path: str = CARDS_CSV_PATH) -> pd.DataFrame:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        df = pd.DataFrame(columns=CARD_COLUMNS)\n",
    "        df.to_csv(path, index=False)\n",
    "        return df\n",
    "    df = pd.read_csv(path)\n",
    "    # Backward/robust handling\n",
    "    for col in CARD_COLUMNS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    # Coerce learned -> bool\n",
    "    if \"learned\" in df.columns:\n",
    "        df[\"learned\"] = df[\"learned\"].apply(lambda x: bool(x) if isinstance(x, (bool,)) else (str(x).lower() == \"true\"))\n",
    "    return df[CARD_COLUMNS]\n",
    "\n",
    "def _save_cards_df(df: pd.DataFrame, path: str = CARDS_CSV_PATH) -> None:\n",
    "    df2 = df.copy()\n",
    "    df2.to_csv(path, index=False)\n",
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "def _normalize_question(q: str) -> str:\n",
    "    q = (q or \"\").strip()\n",
    "    # collapse spaces, strip trailing ?\n",
    "    q = re.sub(r\"\\s+\", \" \", q)\n",
    "    return q\n",
    "\n",
    "def _card_id(url_canonical: str, question: str) -> str:\n",
    "    base = f\"{url_canonical}\\n{_normalize_question(question)}\"\n",
    "    return hashlib.sha1(base.encode(\"utf-8\")).hexdigest()[:16]\n",
    "\n",
    "def _utc_now_iso() -> str:\n",
    "    return datetime.datetime.utcnow().isoformat() + \"Z\"\n",
    "\n",
    "def _safe_json_loads(text: str) -> dict:\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        m = re.search(r\"\\{.*\\}\", text, re.S)\n",
    "        return json.loads(m.group(0)) if m else {\"error\": \"Non-JSON\", \"raw\": text[:1200]}\n",
    "\n",
    "# =========================\n",
    "# LLM: generate Q&A from content_text\n",
    "# =========================\n",
    "_SYSTEM_PROMPT = (\n",
    "    \"You generate concise, factual Q&A flashcards from text. Avoid trivia and ambiguity. \"\n",
    "    \"Prefer concrete facts, key definitions, mechanisms, comparisons, and takeaways. \"\n",
    "    \"Keep questions ≤ 140 characters, answers ≤ 240 characters.\"\n",
    ")\n",
    "\n",
    "_USER_TEMPLATE = \"\"\"From the text below, produce 3–6 Q&A flashcards that capture the core facts/concepts.\n",
    "Return STRICT JSON only:\n",
    "{\"cards\":[{\"q\":\"...\",\"a\":\"...\"}]}\n",
    "\n",
    "Text (may be truncated):\n",
    "{TEXT}\n",
    "\"\"\"\n",
    "\n",
    "def _call_llm_for_cards(content_text: str, model: str = MODEL_FOR_CARDS) -> T.List[T.Dict[str, str]]:\n",
    "    # Use Responses API if available\n",
    "    payload = _USER_TEMPLATE.replace(\"{TEXT}\", (content_text or \"\")[:MAX_TEXT_CHARS])\n",
    "    if hasattr(client, \"responses\"):\n",
    "        resp = client.responses.create(\n",
    "            model=model,\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": _SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": payload}\n",
    "            ],\n",
    "        )\n",
    "        out = getattr(resp, \"output_text\", getattr(resp, \"output\", \"\"))\n",
    "        data = _safe_json_loads(out)\n",
    "    else:\n",
    "        # very old fallback\n",
    "        cc = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": _SYSTEM_PROMPT},\n",
    "                      {\"role\": \"user\", \"content\": payload}]\n",
    "        )\n",
    "        data = _safe_json_loads(cc.choices[0].message.content)\n",
    "\n",
    "    cards = data.get(\"cards\", [])\n",
    "    # lightweight validation & cleaning\n",
    "    clean = []\n",
    "    seen_q = set()\n",
    "    for c in cards:\n",
    "        q = _normalize_question(str(c.get(\"q\", \"\")).strip())\n",
    "        a = str(c.get(\"a\", \"\")).strip()\n",
    "        if not q or not a:\n",
    "            continue\n",
    "        if len(q) > 200 or len(a) > 500:\n",
    "            # discard egregiously long pairs (model might go verbose)\n",
    "            continue\n",
    "        if q.lower() in seen_q:\n",
    "            continue\n",
    "        seen_q.add(q.lower())\n",
    "        clean.append({\"q\": q, \"a\": a})\n",
    "    return clean[:6]  # cap to 6\n",
    "\n",
    "# =========================\n",
    "# Public API\n",
    "# =========================\n",
    "def generate_cards_for_url(url_canonical: str, content_text: str, n: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Idempotent. Generates Q&A with LLM and upserts into cards_store.csv.\n",
    "    Never flips learned=True back to False.\n",
    "    Returns the full cards DataFrame (all cards).\n",
    "    \"\"\"\n",
    "    if not url_canonical or not isinstance(url_canonical, str):\n",
    "        raise ValueError(\"url_canonical must be a non-empty string.\")\n",
    "\n",
    "    df = _ensure_cards_csv(CARDS_CSV_PATH)\n",
    "    # Ask LLM for cards\n",
    "    pairs = _call_llm_for_cards(content_text)\n",
    "    if not pairs:\n",
    "        return df  # nothing to add\n",
    "\n",
    "    # Build new rows; upsert by card_id\n",
    "    existing_ids = set(df[\"card_id\"].astype(str).tolist())\n",
    "    rows_to_add = []\n",
    "    now_iso = _utc_now_iso()\n",
    "\n",
    "    count_added = 0\n",
    "    for pair in pairs:\n",
    "        if count_added >= max(1, n):  # ensure at least 1 if any generated\n",
    "            break\n",
    "        q, a = pair[\"q\"], pair[\"a\"]\n",
    "        cid = _card_id(url_canonical, q)\n",
    "        if cid in existing_ids:\n",
    "            # don't overwrite; skip creating a dup\n",
    "            continue\n",
    "        rows_to_add.append({\n",
    "            \"card_id\": cid,\n",
    "            \"url_canonical\": url_canonical,\n",
    "            \"question\": q,\n",
    "            \"answer\": a,\n",
    "            \"learned\": False,\n",
    "            \"created_at_utc\": now_iso\n",
    "        })\n",
    "        count_added += 1\n",
    "\n",
    "    if rows_to_add:\n",
    "        df = pd.concat([df, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
    "        _save_cards_df(df, CARDS_CSV_PATH)\n",
    "    return df\n",
    "\n",
    "def load_unlearned_cards(url_canonical: str) -> pd.DataFrame:\n",
    "    df = _ensure_cards_csv(CARDS_CSV_PATH)\n",
    "    mask = (df[\"url_canonical\"] == url_canonical) & (~df[\"learned\"])\n",
    "    return df[mask].copy()\n",
    "\n",
    "def start_session(url_canonical: str, shuffle: bool = True) -> deque:\n",
    "    \"\"\"\n",
    "    Returns a deque of dicts: [{\"card_id\",\"question\",\"answer\"}, ...] for unlearned cards.\n",
    "    \"\"\"\n",
    "    df = load_unlearned_cards(url_canonical)\n",
    "    print(f\"Found {len(df)} unlearned cards for {url_canonical}\")\n",
    "    cards = df[[\"card_id\",\"question\",\"answer\"]].to_dict(orient=\"records\")\n",
    "    if shuffle and len(cards) > 1:\n",
    "        import random\n",
    "        random.shuffle(cards)\n",
    "    return deque(cards)\n",
    "\n",
    "def swipe_left(queue: deque) -> None:\n",
    "    \"\"\"\n",
    "    \"Review again\": move the current card to the end of the queue.\n",
    "    No persistence change.\n",
    "    \"\"\"\n",
    "    if not queue:\n",
    "        return\n",
    "    queue.append(queue.popleft())\n",
    "\n",
    "def swipe_right(queue: deque, card_id: str) -> None:\n",
    "    \"\"\"\n",
    "    \"I know it\": mark learned=True in CSV, then remove from the queue.\n",
    "    \"\"\"\n",
    "    if not queue:\n",
    "        return\n",
    "    current = queue[0]\n",
    "    if current[\"card_id\"] != card_id:\n",
    "        # guard: if caller passed mismatched card_id, align to current\n",
    "        card_id = current[\"card_id\"]\n",
    "\n",
    "    # persist learned=True\n",
    "    df = _ensure_cards_csv(CARDS_CSV_PATH)\n",
    "    idx = df.index[df[\"card_id\"] == card_id]\n",
    "    if len(idx) > 0:\n",
    "        df.loc[idx, \"learned\"] = True\n",
    "        _save_cards_df(df, CARDS_CSV_PATH)\n",
    "\n",
    "    # remove from queue\n",
    "    queue.popleft()\n",
    "\n",
    "def count_unlearned(url_canonical: str) -> int:\n",
    "    return len(load_unlearned_cards(url_canonical))\n",
    "\n",
    "def reset_learned(url_canonical: str) -> int:\n",
    "    \"\"\"\n",
    "    Set learned=False for all cards of an article.\n",
    "    Returns the number of cards reset.\n",
    "    \"\"\"\n",
    "    df = _ensure_cards_csv(CARDS_CSV_PATH)\n",
    "    mask = (df[\"url_canonical\"] == url_canonical)\n",
    "    n = int(mask.sum())\n",
    "    if n > 0:\n",
    "        df.loc[mask, \"learned\"] = False\n",
    "        _save_cards_df(df, CARDS_CSV_PATH)\n",
    "    return n\n",
    "\n",
    "# =========================\n",
    "# Mini-Demo (how to use)\n",
    "# =========================\n",
    "# Assume you already ingested an article and have:\n",
    "#   - url_canonical from your canonicalize_url(url)\n",
    "#   - content_text from your ingestion result (df['content_text'] or rec['content_text'])\n",
    "\n",
    "# Example placeholders (replace with your real values):\n",
    "# url_canonical_demo = canonicalize_url(rec[\"url\"])  # if you have canonicalize_url() from your earlier code\n",
    "# content_text_demo  = rec[\"content_text\"]\n",
    "\n",
    "# Generate cards (idempotent; safe to re-run)\n",
    "# generate_cards_for_url(url_canonical_demo, content_text_demo, n=5)\n",
    "\n",
    "# Start a learning session\n",
    "# q = start_session(url_canonical_demo, shuffle=True)\n",
    "# if not q:\n",
    "#     print(\"No unlearned cards. You're done!\")\n",
    "# else:\n",
    "#     # Peek at current card\n",
    "#     cur = q[0]\n",
    "#     print(\"Q:\", cur[\"question\"])\n",
    "#     print(\"A:\", cur[\"answer\"])\n",
    "#     # Simulate user action:\n",
    "#     # swipe_left(q)  # if user wants to review again\n",
    "#     # swipe_right(q, cur[\"card_id\"])  # if user knows it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05012c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/_gt22h7503dgw67xjtv9ccn00000gn/T/ipykernel_6815/2457346259.py:70: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.datetime.utcnow().isoformat() + \"Z\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>url_canonical</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>learned</th>\n",
       "      <th>created_at_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1a8f61e63debc5a3</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "      <td>What is LLM-as-a-Judge?</td>\n",
       "      <td>LLM-as-a-Judge uses large language models to e...</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-09-13T15:55:11.385772Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7a64dabeca7e0612</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "      <td>What are the two main types of LLM-as-a-Judge?</td>\n",
       "      <td>Single-output scoring evaluates one output bas...</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-09-13T15:55:11.385772Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>778d03e73c69b33d</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "      <td>Why use LLM-as-a-Judge over human evaluation o...</td>\n",
       "      <td>LLM-as-a-Judge is more scalable, accurate, and...</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-09-13T15:55:11.385772Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a2e35c695451c833</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "      <td>What inputs are typically provided to an LLM j...</td>\n",
       "      <td>The original input prompt, the generated outpu...</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-09-13T15:55:11.385772Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e614d7e6881a0c5e</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "      <td>How does pairwise LLM-as-a-Judge work?</td>\n",
       "      <td>It compares two or more LLM outputs for the sa...</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-09-13T15:55:11.385772Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f3645bd8a4ed6a5f</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "      <td>What is LLM-as-a-Judge used for?</td>\n",
       "      <td>LLM-as-a-Judge uses large language models to a...</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-09-13T15:55:23.656486Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ff443fcc9b3dbe54</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "      <td>How does single-output referenceless judging w...</td>\n",
       "      <td>It scores one LLM output against a rubric with...</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-09-13T15:55:23.656486Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c9663654e2a81f19</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "      <td>What is the advantage of reference-based singl...</td>\n",
       "      <td>It uses a gold-standard expected output as an ...</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-09-13T15:55:23.656486Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7c1cc5ad8cea707b</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "      <td>Why is LLM-as-a-Judge gaining popularity over ...</td>\n",
       "      <td>LLM judges are scalable, faster, and better ca...</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-09-13T15:55:23.656486Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5e4579936c3e0505</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "      <td>What are common use cases for LLM-as-a-Judge?</td>\n",
       "      <td>It evaluates single-turn or multi-turn LLM int...</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-09-13T15:55:23.656486Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            card_id                                      url_canonical  \\\n",
       "0  1a8f61e63debc5a3  https://www.confident-ai.com/blog/why-llm-as-a...   \n",
       "1  7a64dabeca7e0612  https://www.confident-ai.com/blog/why-llm-as-a...   \n",
       "2  778d03e73c69b33d  https://www.confident-ai.com/blog/why-llm-as-a...   \n",
       "3  a2e35c695451c833  https://www.confident-ai.com/blog/why-llm-as-a...   \n",
       "4  e614d7e6881a0c5e  https://www.confident-ai.com/blog/why-llm-as-a...   \n",
       "5  f3645bd8a4ed6a5f  https://www.confident-ai.com/blog/why-llm-as-a...   \n",
       "6  ff443fcc9b3dbe54  https://www.confident-ai.com/blog/why-llm-as-a...   \n",
       "7  c9663654e2a81f19  https://www.confident-ai.com/blog/why-llm-as-a...   \n",
       "8  7c1cc5ad8cea707b  https://www.confident-ai.com/blog/why-llm-as-a...   \n",
       "9  5e4579936c3e0505  https://www.confident-ai.com/blog/why-llm-as-a...   \n",
       "\n",
       "                                            question  \\\n",
       "0                            What is LLM-as-a-Judge?   \n",
       "1     What are the two main types of LLM-as-a-Judge?   \n",
       "2  Why use LLM-as-a-Judge over human evaluation o...   \n",
       "3  What inputs are typically provided to an LLM j...   \n",
       "4             How does pairwise LLM-as-a-Judge work?   \n",
       "5                   What is LLM-as-a-Judge used for?   \n",
       "6  How does single-output referenceless judging w...   \n",
       "7  What is the advantage of reference-based singl...   \n",
       "8  Why is LLM-as-a-Judge gaining popularity over ...   \n",
       "9      What are common use cases for LLM-as-a-Judge?   \n",
       "\n",
       "                                              answer  learned  \\\n",
       "0  LLM-as-a-Judge uses large language models to e...    False   \n",
       "1  Single-output scoring evaluates one output bas...    False   \n",
       "2  LLM-as-a-Judge is more scalable, accurate, and...    False   \n",
       "3  The original input prompt, the generated outpu...    False   \n",
       "4  It compares two or more LLM outputs for the sa...    False   \n",
       "5  LLM-as-a-Judge uses large language models to a...    False   \n",
       "6  It scores one LLM output against a rubric with...    False   \n",
       "7  It uses a gold-standard expected output as an ...    False   \n",
       "8  LLM judges are scalable, faster, and better ca...    False   \n",
       "9  It evaluates single-turn or multi-turn LLM int...    False   \n",
       "\n",
       "                created_at_utc  \n",
       "0  2025-09-13T15:55:11.385772Z  \n",
       "1  2025-09-13T15:55:11.385772Z  \n",
       "2  2025-09-13T15:55:11.385772Z  \n",
       "3  2025-09-13T15:55:11.385772Z  \n",
       "4  2025-09-13T15:55:11.385772Z  \n",
       "5  2025-09-13T15:55:23.656486Z  \n",
       "6  2025-09-13T15:55:23.656486Z  \n",
       "7  2025-09-13T15:55:23.656486Z  \n",
       "8  2025-09-13T15:55:23.656486Z  \n",
       "9  2025-09-13T15:55:23.656486Z  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_canonical = \"https://www.confident-ai.com/blog/why-llm-as-a-judge-is-the-best-llm-evaluation-method\"\n",
    "df_cards = generate_cards_for_url(url_canonical, row[\"content_text\"], n=5)\n",
    "df_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7227d94",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m q = start_session(url_canonical, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m q:\n\u001b[32m      3\u001b[39m     card = q[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "while q:\n",
    "    card = q[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63329e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([{'card_id': 'c9663654e2a81f19',\n",
       "        'question': 'What is the advantage of reference-based single-output judging?',\n",
       "        'answer': 'It uses a gold-standard expected output as an anchor to improve evaluation consistency and reproducibility when scoring LLM outputs.'},\n",
       "       {'card_id': '1a8f61e63debc5a3',\n",
       "        'question': 'What is LLM-as-a-Judge?',\n",
       "        'answer': 'LLM-as-a-Judge uses large language models to evaluate LLM outputs by scoring them against custom criteria such as accuracy, relevance, and bias.'},\n",
       "       {'card_id': 'ff443fcc9b3dbe54',\n",
       "        'question': 'How does single-output referenceless judging work?',\n",
       "        'answer': 'It scores one LLM output against a rubric without a gold-standard answer, useful for open-ended tasks by evaluating accuracy, coherence, and helpfulness independently.'},\n",
       "       {'card_id': '7c1cc5ad8cea707b',\n",
       "        'question': 'Why is LLM-as-a-Judge gaining popularity over human evaluators and traditional metrics?',\n",
       "        'answer': 'LLM judges are scalable, faster, and better capture deeper semantic quality of generated text compared to costly human evaluation and limited traditional metrics like BLEU or ROUGE.'},\n",
       "       {'card_id': 'a2e35c695451c833',\n",
       "        'question': 'What inputs are typically provided to an LLM judge for single-output evaluation?',\n",
       "        'answer': 'The original input prompt, the generated output from the LLM, and optionally context like retrieved documents or reference outputs.'},\n",
       "       {'card_id': '5e4579936c3e0505',\n",
       "        'question': 'What are common use cases for LLM-as-a-Judge?',\n",
       "        'answer': 'It evaluates single-turn or multi-turn LLM interactions, such as scoring chatbot replies, summarization coherence, or multi-turn conversational quality in customer support bots.'},\n",
       "       {'card_id': 'e614d7e6881a0c5e',\n",
       "        'question': 'How does pairwise LLM-as-a-Judge work?',\n",
       "        'answer': 'It compares two or more LLM outputs for the same input and selects the better one without scoring, similar to automated versions of LLM arenas.'},\n",
       "       {'card_id': '778d03e73c69b33d',\n",
       "        'question': 'Why use LLM-as-a-Judge over human evaluation or traditional metrics?',\n",
       "        'answer': 'LLM-as-a-Judge is more scalable, accurate, and reliable than slow, costly human annotation and traditional metrics like BLEU or ROUGE.'},\n",
       "       {'card_id': 'f3645bd8a4ed6a5f',\n",
       "        'question': 'What is LLM-as-a-Judge used for?',\n",
       "        'answer': 'LLM-as-a-Judge uses large language models to automatically score LLM outputs based on custom evaluation criteria like relevance, faithfulness, bias, and correctness.'},\n",
       "       {'card_id': '7a64dabeca7e0612',\n",
       "        'question': 'What are the two main types of LLM-as-a-Judge?',\n",
       "        'answer': 'Single-output scoring evaluates one output based on a rubric, either with or without reference. Pairwise comparison chooses the better output between two LLM results.'}])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = start_session(url_canonical, shuffle=True)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60172026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Button-based swipe UI (requires ipywidgets) ===\n",
    "# If needed: pip install ipywidgets && jupyter nbextension enable --py widgetsnbextension\n",
    "from ipywidgets import Button, HBox, VBox, HTML, Output\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def run_widget_session(url_canonical, shuffle=True):\n",
    "    queue = start_session(url_canonical, shuffle=shuffle)\n",
    "    out = Output()\n",
    "\n",
    "    if not queue:\n",
    "        display(HTML(\"<b>No unlearned cards for this article. 🎉</b>\"))\n",
    "        return\n",
    "\n",
    "    # widgets\n",
    "    q_html = HTML(\"<h4>Question</h4>\")\n",
    "    a_html = HTML(\"<i>(click 'Reveal answer')</i>\")\n",
    "    a_shown = {\"val\": False}\n",
    "\n",
    "    btn_reveal = Button(description=\"Reveal answer\", button_style=\"\")\n",
    "    btn_know   = Button(description=\"I know it 👍\", button_style=\"success\")\n",
    "    btn_review = Button(description=\"Review again 🔁\", button_style=\"warning\")\n",
    "\n",
    "    # helpers\n",
    "    def render_current():\n",
    "        if not queue:\n",
    "            with out:\n",
    "                clear_output()\n",
    "                display(HTML(\"<b>All cards learned for this article. 🎉</b>\"))\n",
    "            # disable buttons\n",
    "            btn_reveal.disabled = True\n",
    "            btn_know.disabled   = True\n",
    "            btn_review.disabled = True\n",
    "            return\n",
    "\n",
    "        card = queue[0]\n",
    "        q_html.value = f\"<h4>Question</h4><div>{card['question']}</div>\"\n",
    "        a_html.value = \"<i>(click 'Reveal answer')</i>\"\n",
    "        a_shown[\"val\"] = False\n",
    "\n",
    "    def on_reveal(_):\n",
    "        if not queue:\n",
    "            return\n",
    "        card = queue[0]\n",
    "        a_html.value = f\"<b>Answer</b><div style='margin-top:6px;'>{card['answer']}</div>\"\n",
    "        a_shown[\"val\"] = True\n",
    "\n",
    "    def on_know(_):\n",
    "        if not queue:\n",
    "            return\n",
    "        card = queue[0]\n",
    "        swipe_right(queue, card[\"card_id\"])   # persist learned=True and pop from queue\n",
    "        render_current()\n",
    "\n",
    "    def on_review(_):\n",
    "        if not queue:\n",
    "            return\n",
    "        swipe_left(queue)                     # move current to end\n",
    "        render_current()\n",
    "\n",
    "    btn_reveal.on_click(on_reveal)\n",
    "    btn_know.on_click(on_know)\n",
    "    btn_review.on_click(on_review)\n",
    "\n",
    "    with out:\n",
    "        clear_output()\n",
    "        render_current()\n",
    "        display(VBox([\n",
    "            q_html,\n",
    "            a_html,\n",
    "            HBox([btn_reveal, btn_know, btn_review])\n",
    "        ]))\n",
    "\n",
    "    display(out)\n",
    "\n",
    "# usage:\n",
    "# run_widget_session(url_canonical, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56abe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_widget_session(url_canonical, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed3b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f371bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CLI-style swipe loop (works in any notebook) ===\n",
    "def run_text_session(url_canonical):\n",
    "    q = start_session(url_canonical, shuffle=True)\n",
    "    if not q:\n",
    "        print(\"No unlearned cards for this article. 🎉\")\n",
    "        return\n",
    "\n",
    "    print(f\"Session loaded with {len(q)} cards. Type:\\n\"\n",
    "          \"  s = show answer, r = I know it (remove), l = review again (send to end), q = quit\\n\")\n",
    "\n",
    "    while q:\n",
    "        card = q[0]\n",
    "        print(\"\\nQ:\", card[\"question\"])\n",
    "        cmd = input(\"Command [s/r/l/q]: \").strip().lower()\n",
    "\n",
    "        if cmd == \"q\":\n",
    "            print(\"Exited.\")\n",
    "            break\n",
    "        elif cmd == \"s\":\n",
    "            print(\"A:\", card[\"answer\"])\n",
    "        elif cmd == \"r\":\n",
    "            swipe_right(q, card[\"card_id\"])\n",
    "            print(\"✅ Marked learned. Remaining:\", len(q))\n",
    "        elif cmd == \"l\":\n",
    "            swipe_left(q)\n",
    "            print(\"🔁 Moved to end. Queue size:\", len(q))\n",
    "        else:\n",
    "            print(\"Unknown command. Use s/r/l/q.\")\n",
    "\n",
    "    if not q:\n",
    "        print(\"\\nAll cards learned for this article. 🎉\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b446bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage:\n",
    "run_text_session(url_canonical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b8c4e2",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f5e74c",
   "metadata": {},
   "source": [
    "## Function1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb50b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === deps (assumes you've already installed: openai, trafilatura, bs4, lxml or html5lib, python-dotenv) ===\n",
    "# import os, re, json, datetime, typing as T\n",
    "# from dataclasses import dataclass, asdict\n",
    "# from urllib.parse import urlparse\n",
    "\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import trafilatura\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# # ------------ Parser selection (robust) ------------\n",
    "# def _best_bs4_parser():\n",
    "#     try:\n",
    "#         import lxml  # noqa: F401\n",
    "#         return \"lxml\"\n",
    "#     except Exception:\n",
    "#         try:\n",
    "#             import html5lib  # noqa: F401\n",
    "#             return \"html5lib\"\n",
    "#         except Exception:\n",
    "#             return \"html.parser\"\n",
    "\n",
    "# # ------------ Models & settings ------------\n",
    "# MODEL_WITH_WEB = \"gpt-4o-mini\"   # has web tool on supported accounts\n",
    "# MODEL_FALLBACK  = \"gpt-4.1-mini\" # summarization if web tool unavailable\n",
    "\n",
    "# STRICT_JSON_RULES = (\n",
    "#     \"Return STRICT JSON with keys: \"\n",
    "#     '[\"title\",\"author\",\"publish_date\",\"categories\",\"tags\",\"tldr\",\"language\",\"citations\",\"confidence_notes\"]. '\n",
    "#     \"categories=1–3 short labels; tags=5–12 keywords; tldr=3–6 crisp bullets; \"\n",
    "#     \"language=two-letter ISO code; citations=list of {title,url}; \"\n",
    "#     \"confidence_notes=1–2 short sentences. No markdown—JSON only.\"\n",
    "# )\n",
    "\n",
    "# DEFAULT_HEADERS = {\n",
    "#     \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:128.0) Gecko/20100101 Firefox/128.0\"\n",
    "# }\n",
    "\n",
    "# @dataclass\n",
    "# class PageContent:\n",
    "#     url: str\n",
    "#     domain: str\n",
    "#     title: T.Optional[str]\n",
    "#     author: T.Optional[str]\n",
    "#     publish_date: T.Optional[str]\n",
    "#     text: str\n",
    "#     html_len: int\n",
    "#     text_len: int\n",
    "#     _html: T.Optional[str] = None\n",
    "\n",
    "# # ------------ Helpers ------------\n",
    "# def _safe_json_loads(text: str) -> dict:\n",
    "#     try:\n",
    "#         return json.loads(text)\n",
    "#     except Exception:\n",
    "#         m = re.search(r\"\\{.*\\}\", text, re.S)\n",
    "#         return json.loads(m.group(0)) if m else {\"error\": \"Non-JSON output\", \"raw\": text[:1200]}\n",
    "\n",
    "# def _fetch_html(url: str) -> str:\n",
    "#     r = requests.get(url, headers=DEFAULT_HEADERS, timeout=25)\n",
    "#     r.raise_for_status()\n",
    "#     return r.text\n",
    "\n",
    "# def _guess_meta(soup: BeautifulSoup) -> dict:\n",
    "#     meta = {\"title\": None, \"author\": None, \"publish_date\": None}\n",
    "#     # title\n",
    "#     if soup.title and soup.title.string:\n",
    "#         meta[\"title\"] = soup.title.string.strip()\n",
    "#     ogt = soup.find(\"meta\", property=\"og:title\")\n",
    "#     if ogt and ogt.get(\"content\"):\n",
    "#         meta[\"title\"] = ogt[\"content\"].strip()\n",
    "#     # author\n",
    "#     for k in [\"author\", \"article:author\", \"og:article:author\"]:\n",
    "#         m = soup.find(\"meta\", attrs={\"name\": k}) or soup.find(\"meta\", attrs={\"property\": k})\n",
    "#         if m and m.get(\"content\"):\n",
    "#             meta[\"author\"] = m[\"content\"].strip(); break\n",
    "#     # date\n",
    "#     for k in [\"article:published_time\", \"og:published_time\", \"pubdate\", \"publish-date\", \"date\"]:\n",
    "#         m = soup.find(\"meta\", attrs={\"name\": k}) or soup.find(\"meta\", attrs={\"property\": k})\n",
    "#         if m and m.get(\"content\"):\n",
    "#             meta[\"publish_date\"] = m[\"content\"].strip(); break\n",
    "#     if meta[\"publish_date\"] is None:\n",
    "#         t = soup.find(\"time\")\n",
    "#         if t and (t.get(\"datetime\") or t.text):\n",
    "#             meta[\"publish_date\"] = (t.get(\"datetime\") or t.text).strip()\n",
    "#     return meta\n",
    "\n",
    "# def extract_readable_text(url: str, include_html: bool=False) -> PageContent:\n",
    "#     html = _fetch_html(url)\n",
    "\n",
    "#     # 1) trafilatura (best effort)\n",
    "#     text = (trafilatura.extract(\n",
    "#         html, include_comments=False, include_tables=False, favor_precision=True\n",
    "#     ) or \"\").strip()\n",
    "\n",
    "#     # 2) fallback: BeautifulSoup\n",
    "#     if len(text) < 200:\n",
    "#         PARSER = _best_bs4_parser()\n",
    "#         soup = BeautifulSoup(html, PARSER)\n",
    "#         for tag in soup([\"script\",\"style\",\"noscript\",\"header\",\"footer\",\"nav\",\"aside\"]):\n",
    "#             tag.extract()\n",
    "#         text = soup.get_text(\"\\n\", strip=True)\n",
    "\n",
    "#     PARSER = _best_bs4_parser()\n",
    "#     soup_full = BeautifulSoup(html, PARSER)\n",
    "#     meta = _guess_meta(soup_full)\n",
    "\n",
    "#     text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "#     return PageContent(\n",
    "#         url=url,\n",
    "#         domain=urlparse(url).netloc,\n",
    "#         title=meta[\"title\"],\n",
    "#         author=meta[\"author\"],\n",
    "#         publish_date=meta[\"publish_date\"],\n",
    "#         text=text,\n",
    "#         html_len=len(html or \"\"),\n",
    "#         text_len=len(text or \"\"),\n",
    "#         _html=html if include_html else None\n",
    "#     )\n",
    "\n",
    "# # ------------ Web tool path (no response_format to be version-agnostic) ------------\n",
    "# def analyze_link_with_web_tool(url: str) -> dict:\n",
    "#     if not hasattr(client, \"responses\"):\n",
    "#         raise RuntimeError(\"responses_api_unavailable\")\n",
    "\n",
    "#     base_kwargs = dict(\n",
    "#         model=MODEL_WITH_WEB,\n",
    "#         tools=[{\"type\": \"web_search\"}],\n",
    "#         input=[\n",
    "#             {\"role\": \"system\", \"content\": \"You are a precise analyst that reads the provided URL using the web tool.\"},\n",
    "#             {\"role\": \"user\", \"content\": f\"{STRICT_JSON_RULES}\\n\\nRead this URL and summarize it with citations: {url}\"}\n",
    "#         ],\n",
    "#     )\n",
    "#     resp = client.responses.create(**base_kwargs)\n",
    "#     # Some SDKs expose .output_text, others .output; handle both:\n",
    "#     output_text = getattr(resp, \"output_text\", getattr(resp, \"output\", \"\"))\n",
    "#     return _safe_json_loads(output_text)\n",
    "\n",
    "# # ------------ Fallback summarization (local content + LLM) ------------\n",
    "# def summarize_local_content(page: PageContent) -> dict:\n",
    "#     payload = {\n",
    "#         \"source_url\": page.url,\n",
    "#         \"detected_title\": page.title,\n",
    "#         \"detected_author\": page.author,\n",
    "#         \"detected_publish_date\": page.publish_date,\n",
    "#         \"article_text\": page.text[:22_000]\n",
    "#     }\n",
    "#     if hasattr(client, \"responses\"):\n",
    "#         resp = client.responses.create(\n",
    "#             model=MODEL_FALLBACK,\n",
    "#             input=[\n",
    "#                 {\"role\": \"system\", \"content\": STRICT_JSON_RULES},\n",
    "#                 {\"role\": \"user\", \"content\": json.dumps(payload)}\n",
    "#             ],\n",
    "#         )\n",
    "#         output_text = getattr(resp, \"output_text\", getattr(resp, \"output\", \"\"))\n",
    "#         return _safe_json_loads(output_text)\n",
    "#     else:\n",
    "#         # Very old SDK fallback via Chat Completions\n",
    "#         messages = [\n",
    "#             {\"role\": \"system\", \"content\": STRICT_JSON_RULES},\n",
    "#             {\"role\": \"user\", \"content\": json.dumps(payload)},\n",
    "#         ]\n",
    "#         cc = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "#         return _safe_json_loads(cc.choices[0].message.content)\n",
    "\n",
    "# # ------------ Public API returning BOTH LLM + content ------------\n",
    "# def analyze_link_plus(url: str, include_html: bool=False, text_cap: int=50_000) -> dict:\n",
    "#     \"\"\"\n",
    "#     Returns:\n",
    "#     {\n",
    "#       \"llm\": {...},                # categories/tags/tldr/etc.\n",
    "#       \"content\": {\n",
    "#           \"url\",\"domain\",\"meta\":{\"title\",\"author\",\"publish_date\"},\n",
    "#           \"text\",\"text_len\",\"html_len\", [\"html\" if include_html=True]\n",
    "#       },\n",
    "#       \"_source\": {...}             # mode + bookkeeping\n",
    "#     }\n",
    "#     \"\"\"\n",
    "#     assert url.startswith(\"http\"), \"Pass a valid http(s) URL.\"\n",
    "\n",
    "#     # Always build content locally so you can verify tags/summary\n",
    "#     page = extract_readable_text(url, include_html=include_html)\n",
    "#     content_block = {\n",
    "#         \"url\": page.url,\n",
    "#         \"domain\": page.domain,\n",
    "#         \"meta\": {\"title\": page.title, \"author\": page.author, \"publish_date\": page.publish_date},\n",
    "#         \"text\": page.text[:text_cap],                   # cap returned text to keep memory manageable\n",
    "#         \"text_len\": page.text_len,\n",
    "#         \"html_len\": page.html_len,\n",
    "#     }\n",
    "#     if include_html and page._html is not None:\n",
    "#         content_block[\"html\"] = page._html  # careful: can be huge\n",
    "\n",
    "#     # Try web tool first for the LLM output\n",
    "#     try:\n",
    "#         llm_data = analyze_link_with_web_tool(url)\n",
    "#         mode = \"openai_web_tool\"\n",
    "#         model_used = MODEL_WITH_WEB\n",
    "#     except Exception:\n",
    "#         if page.text_len < 200:\n",
    "#             raise RuntimeError(\"Could not extract enough text; page may be paywalled or script-rendered.\")\n",
    "#         llm_data = summarize_local_content(page)\n",
    "#         # fill missing fields\n",
    "#         llm_data.setdefault(\"title\", page.title)\n",
    "#         llm_data.setdefault(\"author\", page.author)\n",
    "#         llm_data.setdefault(\"publish_date\", page.publish_date)\n",
    "#         llm_data.setdefault(\"citations\", [{\"title\": page.title or \"\", \"url\": page.url}])\n",
    "#         mode = \"local_fallback\"\n",
    "#         model_used = MODEL_FALLBACK\n",
    "\n",
    "#     result = {\n",
    "#         \"llm\": llm_data,\n",
    "#         \"content\": content_block,\n",
    "#         \"_source\": {\n",
    "#             \"mode\": mode,\n",
    "#             \"model\": model_used,\n",
    "#             \"url\": page.url,\n",
    "#             \"domain\": page.domain,\n",
    "#             \"fetched_at\": datetime.datetime.utcnow().isoformat() + \"Z\"\n",
    "#         }\n",
    "#     }\n",
    "#     return result\n",
    "\n",
    "\n",
    "# test_url = \"https://www.confident-ai.com/blog/why-llm-as-a-judge-is-the-best-llm-evaluation-method\"\n",
    "# out = analyze_link_plus(test_url, include_html=False, text_cap=40000)\n",
    "# print(json.dumps(out[\"llm\"], indent=2, ensure_ascii=False))\n",
    "# print(\"---\\nCONTENT META:\", json.dumps(out[\"content\"][\"meta\"], indent=2, ensure_ascii=False))\n",
    "# print(\"TEXT PREVIEW:\\n\", out[\"content\"][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc2112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/_gt22h7503dgw67xjtv9ccn00000gn/T/ipykernel_6815/3911997558.py:291: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  fetched_at_utc = datetime.datetime.utcnow().isoformat() + \"Z\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fetched_at_utc</th>\n",
       "      <th>headline</th>\n",
       "      <th>categories</th>\n",
       "      <th>tags</th>\n",
       "      <th>tldr</th>\n",
       "      <th>content_text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-13T15:06:49.176125Z</td>\n",
       "      <td>LLM-as-a-Judge Simply Explained: The Complete ...</td>\n",
       "      <td>[AI/ML, Product, Startups]</td>\n",
       "      <td>[LLM, RAG, LangGraph, Agentic AI, Vector DB, P...</td>\n",
       "      <td>[LLM-as-a-Judge automates LLM evaluation, enha...</td>\n",
       "      <td>Your LLM app is streaming out tokens faster th...</td>\n",
       "      <td>https://www.confident-ai.com/blog/why-llm-as-a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fetched_at_utc  \\\n",
       "0  2025-09-13T15:06:49.176125Z   \n",
       "\n",
       "                                            headline  \\\n",
       "0  LLM-as-a-Judge Simply Explained: The Complete ...   \n",
       "\n",
       "                   categories  \\\n",
       "0  [AI/ML, Product, Startups]   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [LLM, RAG, LangGraph, Agentic AI, Vector DB, P...   \n",
       "\n",
       "                                                tldr  \\\n",
       "0  [LLM-as-a-Judge automates LLM evaluation, enha...   \n",
       "\n",
       "                                        content_text  \\\n",
       "0  Your LLM app is streaming out tokens faster th...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.confident-ai.com/blog/why-llm-as-a...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # =========================\n",
    "# # Quick smoke test / demo (Notebook-friendly)\n",
    "# # =========================\n",
    "\n",
    "# # 1) load taxonomy (or init if empty)\n",
    "# tax = load_taxonomy(TAXONOMY_PATH)\n",
    "# if not tax[\"categories\"]:\n",
    "#     tax[\"categories\"] = [\"AI/ML\",\"Product\",\"Startups\",\"Career\",\"Health\",\"Finance\"]\n",
    "# if not tax[\"tags\"]:\n",
    "#     tax[\"tags\"] = [\"LLM\",\"RAG\",\"LangGraph\",\"Agentic AI\",\"Vector DB\",\"Prompting\",\"A/B Testing\",\"Retention\"]\n",
    "# save_taxonomy(tax[\"categories\"], tax[\"tags\"], TAXONOMY_PATH)\n",
    "\n",
    "# # 2) test a URL\n",
    "# test_url = \"https://www.confident-ai.com/blog/why-llm-as-a-judge-is-the-best-llm-evaluation-method\"\n",
    "\n",
    "# rec = analyze_link_plus(\n",
    "#     test_url,\n",
    "#     allowed_categories=tax[\"categories\"],\n",
    "#     allowed_tags=tax[\"tags\"]\n",
    "# )\n",
    "\n",
    "# # 3) update taxonomy (so new categories/tags are remembered)\n",
    "# tax[\"categories\"] = rec[\"_taxonomy\"][\"updated_categories\"]\n",
    "# tax[\"tags\"] = rec[\"_taxonomy\"][\"updated_tags\"]\n",
    "# save_taxonomy(tax[\"categories\"], tax[\"tags\"], TAXONOMY_PATH)\n",
    "\n",
    "# # 4) convert to DataFrame directly\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame([{\n",
    "#     \"fetched_at_utc\": rec[\"fetched_at_utc\"],\n",
    "#     \"headline\": rec[\"headline\"],\n",
    "#     \"categories\": rec[\"categories\"],\n",
    "#     \"tags\": rec[\"tags\"],\n",
    "#     \"tldr\": rec[\"tldr\"],\n",
    "#     \"content_text\": rec[\"content_text\"],\n",
    "#     \"url\": rec[\"url\"]\n",
    "# }])\n",
    "\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2128f45b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "what_to_eat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
